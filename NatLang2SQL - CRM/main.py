import os
import streamlit as st
import sqlite3 
import operator
from dotenv import load_dotenv
from typing import Annotated, List, TypedDict
from langchain_groq import ChatGroq
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.graph import StateGraph, END, START
from langgraph.prebuilt import ToolNode
from langchain.tools import tool

DB_FILE = "crm_database.db" 

st.set_page_config(page_title="Project Linguagem Natural to SQL", page_icon=":100:", layout="wide")
st.title("Project Linguagem Natural to SQL ")
st.title("Gerenciamento de Mem√≥ria e Contexto - Sistema Multi-Agentes de IA com LangGraph Para Automa√ß√£o do CRM e Consulta a Banco de Dados")

load_dotenv()

class AgentState(TypedDict):
    messages: Annotated[List[BaseMessage], operator.add]

@tool
def query_crm_database(sql_query: str) -> str:
    # recebe uma string de consulta SQL e retorna uma string com o resultado
    """
    Executa uma consulta SQL SOMENTE do tipo SELECT no banco de dados CRM SQLite
    e retorna os resultados.
    Usamos esta ferramenta para obter informa√ß√µes sobre clientes ou intera√ß√µes.
    
    Tabelas dispon√≠veis:

    1. tb_clientes (colunas: customer_id, name, email, phone, company, status, created_at)
       - status pode ser 'Lead', 'Active', 'Inactive', 'Prospect'
    2. tb_interacoes (colunas: interaction_id, customer_id, interaction_date, type, notes)
       - type pode ser 'Email', 'Call', 'Meeting', 'Note'

    Importante: Forne√ßa APENAS consultas SQL `SELECT`. N√£o use `UPDATE`, `DELETE`, `INSERT` ou `DROP`.

    Exemplo de consulta SQL v√°lida:
    'SELECT name, email FROM tb_clientes WHERE status = \\'Active\\';'
    'SELECT i.interaction_date, i.type, i.notes FROM tb_interacoes i JOIN tb_clientes c ON i.customer_id = c.customer_id WHERE c.name = \\'Jo√£o Silva\\' ORDER BY i.interaction_date DESC;'
    """
    print(f"--- Ferramenta query_crm_database recebendo SQL: {sql_query} ---")

    if not sql_query.strip().upper().startswith("SELECT"):
        print("!!! ERRO DE SEGURAN√áA: Tentativa de executar SQL n√£o-SELECT !!!")
        return "Erro: Esta ferramenta s√≥ pode executar consultas SELECT."
    conn = None

    try:
        if not os.path.exists(DB_FILE):
            return f"Erro: Arquivo do banco de dados '{DB_FILE}' n√£o encontrado. Execute o script 'create_crm_db.py' primeiro."

        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute(sql_query)

        results = cursor.fetchall()
        if not results:
            return "Nenhum resultado encontrado para a consulta."

        else:
            column_names = [description[0] for description in cursor.description]
            header = " | ".join(column_names)

            # Converte cada linha de resultados em string, separando campos por " | "
            rows_str = [" | ".join(map(str, row)) for row in results]
            max_results = 15

            output = f"Resultados da consulta ({len(results)} encontrados):\n{header}\n" + "\n".join(rows_str[:max_results])

            if len(results) > max_results:
                output += f"\n... (mais {len(results) - max_results} resultados omitidos)"
            return output

    except sqlite3.Error as e:
        print(f"!!! ERRO SQL: {e} ao executar '{sql_query}' !!!")
        return f"Erro ao executar a consulta SQL: {e}. Verifique a sintaxe da sua consulta e os nomes das tabelas/colunas."
    except Exception as e:
        print(f"!!! ERRO Inesperado na ferramenta: {e} !!!")
        return f"Ocorreu um erro inesperado na ferramenta de banco de dados: {e}"
    finally:
        if conn:
            conn.close()

tools = [query_crm_database]
tool_node = ToolNode(tools)

def cria_agente_runnable(llm, system_prompt):

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt),
            MessagesPlaceholder(variable_name = "messages"),
        ]
    )
    agent_runnable = prompt | llm.bind_tools(tools)

    return agent_runnable

def groq_agent_node(state: AgentState):

    print("\n *** Executando o N√≥ Groq (CRM) *** \n")
    try:
        llm_groq = ChatGroq(model_name="openai/gpt-oss-20b", temperature=0.2) 
        
        system_prompt = """Voc√™ √© um assistente de CRM chamado Groq (modelo Llama3).
        Sua principal fun√ß√£o √© responder perguntas sobre clientes e intera√ß√µes consultando o banco de dados CRM.
        Use a ferramenta 'query_crm_database' fornecendo uma consulta SQL SELECT v√°lida para buscar as informa√ß√µes pedidas.
        Consulte a descri√ß√£o da ferramenta para ver o schema do banco de dados (tabelas: tb_clientes, tb_interacoes e suas colunas).
        Seja direto e baseie suas respostas nos dados retornados pela ferramenta. Se a ferramenta retornar um erro, informe o usu√°rio.
        N√£o invente informa√ß√µes se elas n√£o estiverem no banco de dados.
        """
        
        agent_runnable = cria_agente_runnable(llm_groq, system_prompt)

        print("Runnable Groq (CRM) criado. Invocando...")
        response = agent_runnable.invoke({"messages": state['messages']})
        
        print(f"N√≥ Groq (CRM) Obteve Resposta: Tipo = {type(response)}, Conte√∫do = '{response.content[:50]}...'")
        
        if hasattr(response, 'tool_calls') and response.tool_calls:
            print(f"N√≥ Groq (CRM) est√° chamando a ferramenta: {response.tool_calls}")
        
        return {"messages": [response]}

    except Exception as e:
        print(f"!!! ERRO NO N√ì Groq (CRM): {e} !!!")
        st.error(f"Ocorreu um erro ao contactar a API Groq: {e}")
        error_msg = AIMessage(content = f"[ERRO INTERNO GROQ]: N√£o foi poss√≠vel processar com Groq. Detalhe: {e}", name = "ErroGroq")

        return {"messages": [error_msg]}

def openai_agent_node(state: AgentState):

    print("\n--- Executando N√≥ Agente OpenAI (CRM) ---")
    
    try:

        # Inicializa o LLM OpenAI com temperatura baixa e chave de API

        llm_openai = ChatOpenAI(model_name = 'qwen/qwen3-4b-2507',
                openai_api_base = "http://172.30.64.1:1234/v1",
                openai_api_key = "lm-studio",
                temperature = 0.0,
                max_tokens = -1)

        
        system_prompt = """Voc√™ √© um assistente de CRM experiente chamado OpenAI (modelo GPT).
        Seu objetivo √© ajudar o usu√°rio com informa√ß√µes do banco de dados CRM.
        Utilize a ferramenta 'query_crm_database' para executar consultas SQL SELECT e buscar dados sobre clientes ou intera√ß√µes.
        Refira-se √† descri√ß√£o da ferramenta para entender o schema do banco (tabelas: tb_clientes, tb_interacoes; colunas relevantes como name, email, status, interaction_date, type, notes).
        Formule consultas SQL SELECT precisas com base na pergunta do usu√°rio.
        Apresente os resultados de forma clara. Se encontrar um erro da ferramenta, comunique-o.
        Se a informa√ß√£o n√£o estiver dispon√≠vel, indique isso claramente.
        """
        agent_runnable = cria_agente_runnable(llm_openai, system_prompt)

        print("Runnable OpenAI (CRM) criado. Invocando...")
        response = agent_runnable.invoke({"messages": state['messages']})

        print(f"N√≥ OpenAI (CRM) Obteve Resposta: Tipo={type(response)}, Conte√∫do='{response.content[:50]}...'")
        
        if hasattr(response, 'tool_calls') and response.tool_calls:
            print(f"N√≥ OpenAI (CRM) est√° chamando a ferramenta: {response.tool_calls}")
        
        return {"messages": [response]}

    except Exception as e:
        print(f"!!! ERRO NO N√ì OpenAI (CRM): {e} !!!")
        st.error(f"Ocorreu um erro ao contactar a API OpenAI: {e}")
        error_msg = AIMessage(content=f"[ERRO INTERNO OPENAI]: N√£o foi poss√≠vel processar com OpenAI. Detalhe: {e}", name="ErroOpenAI")

        return {"messages": [error_msg]}

def route_junction_node(state: AgentState) -> dict:
    """Fun√ß√£o para cria√ß√£o do n√≥ de roteamento - grafo onde ocorre a decis√£o central"""
    print("--- N√≥ de Jun√ß√£o de Roteamento (Sem Mudan√ßa de Estado) ---")
    return {}

def router_logic(state: AgentState) -> str:
    print("\n--- Fun√ß√£o L√≥gica de Roteamento (Decidindo Pr√≥ximo Passo) ---")

    messages = state['messages']
    last_message = messages[-1] if messages else None
    if not last_message:
        print("Decis√£o L√≥gica: Sem mensagens no estado, terminando.")
        return "__end__"

    print(f"Roteador analisando √∫ltima mensagem: Tipo={type(last_message).__name__}, Conte√∫do='{last_message.content[:80]}...'")

    if isinstance(last_message, AIMessage) and hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        print("Decis√£o L√≥gica: √öltima mensagem AI tem 'tool_calls'. Roteando para Ferramentas.")
        return "tools"
    if isinstance(last_message, AIMessage):
        print("Decis√£o L√≥gica: Resposta final da IA recebida (sem tool_calls). Terminando o ciclo atual.")
        return "__end__"

    if isinstance(last_message, HumanMessage):
        user_input_current = last_message.content.lower()
        print(f"Analisando √∫ltima mensagem humana para men√ß√µes: '{user_input_current}'")
        if "@openai" in user_input_current:
            print("Decis√£o L√≥gica: Roteando para OpenAI (men√ß√£o expl√≠cita na √∫ltima mensagem)")
            return "openai_agent"
        elif "@groq" in user_input_current:
            print("Decis√£o L√≥gica: Roteando para Groq (men√ß√£o expl√≠cita na √∫ltima mensagem)")
            return "groq_agent"

    if isinstance(last_message, ToolMessage):
        print("Decis√£o L√≥gica: Resultado da ferramenta recebido, roteando para um agente (via altern√¢ncia)...")

    ai_message_count = sum(1 for msg in messages if isinstance(msg, AIMessage))
    print(f"Contagem atual de mensagens AI para altern√¢ncia: {ai_message_count}")

    if ai_message_count % 2 == 0:
        print(f"Decis√£o L√≥gica: Roteando para Groq (padr√£o/alternado)")
        return "groq_agent"
    else:
        print(f"Decis√£o L√≥gica: Roteando para OpenAI (padr√£o/alternado)")
        return "openai_agent"
    
def compila_grafo():

    workflow = StateGraph(AgentState)
    workflow.add_node("openai_agent", openai_agent_node)
    workflow.add_node("groq_agent", groq_agent_node)
    workflow.add_node("tools", tool_node)
    workflow.add_node("router", route_junction_node)
    workflow.add_edge(START, "router")
    workflow.add_conditional_edges(
        "router",
        router_logic,
        {
            "tools": "tools",
            "groq_agent": "groq_agent",
            "openai_agent": "openai_agent",
            "__end__": END
        },
    )
    
    workflow.add_edge("openai_agent", "router")
    workflow.add_edge("groq_agent", "router")
    workflow.add_edge("tools", "router")
    app = workflow.compile()

    print("Grafo Compilado com Sucesso!")

    return app

if "app" not in st.session_state:

    if not os.path.exists(DB_FILE):
        st.error(f"Erro: O arquivo do banco de dados '{DB_FILE}' n√£o foi encontrado.")
        st.info("Por favor, execute o script 'create_crm_db.py' no mesmo diret√≥rio para criar o banco de dados e depois recarregue esta p√°gina.")
        st.stop()

    st.write("Inicializando o grafo pela primeira vez...")

    try:
        st.session_state.app = compila_grafo()
        st.session_state.thread_id = "streamlit_thread_crm"

        if "chat_history" not in st.session_state:
            st.session_state.chat_history = [
                AIMessage(content="Ol√°! Sou seu assistente de CRM. Pergunte-me sobre clientes ou intera√ß√µes (ex: 'Quais clientes est√£o ativos?', 'Mostre as intera√ß√µes de Jo√£o Silva').")
            ]
        st.success("Grafo CRM inicializado.")
    
    except Exception as e:
        st.error(f"Erro cr√≠tico ao construir o grafo CRM: {e}")
        st.exception(e)
        st.stop()

st.sidebar.title("Mem√≥ria")

with st.sidebar.expander("üìú Ver Hist√≥rico Completo da Conversa", expanded=False):
    if st.session_state.chat_history:
        for i, msg in enumerate(st.session_state.chat_history):
            role = "ai" if isinstance(msg, AIMessage) else ("tool" if isinstance(msg, ToolMessage) else "user")
            sender_display = "Usu√°rio"
            if role == "ai":
                ai_message_index = sum(1 for m in st.session_state.chat_history[:i] if isinstance(m, AIMessage))
                is_groq_explicit = "@groq" in msg.content.lower()
                is_openai_explicit = "@openai" in msg.content.lower()
                msg_name = getattr(msg, 'name', None)
                
                if is_groq_explicit or (not is_openai_explicit and ai_message_index % 2 == 0 and not msg_name):
                    sender_display = "AI (Groq/Llama3)"
                elif is_openai_explicit or (not is_groq_explicit and ai_message_index % 2 != 0 and not msg_name):
                    sender_display = "AI (OpenAI/GPT)"
                elif msg_name:
                    sender_display = f"AI ({msg_name})"
                else:
                    sender_display = "AI (Assistente)"
            
            elif role == "tool":
                tool_name = getattr(msg, 'name', 'query_crm_database')
                sender_display = f"Ferramenta ({tool_name})"
            st.markdown(f"**{sender_display}:**")
            
            st.text_area(label=f"msg_{i}", value=msg.content, height=100, disabled=True, label_visibility="collapsed")
            
            if isinstance(msg, AIMessage) and getattr(msg, 'tool_calls', None):
                st.write("*Chamada(s) de Ferramenta:*")
                st.json([{'name': tc.get('name', 'N/A'), 'args': tc.get('args', {})} for tc in msg.tool_calls])
            
            if isinstance(msg, ToolMessage) and hasattr(msg, 'tool_call_id'):
                st.caption(f"ID da Chamada: {msg.tool_call_id}")
            
            st.divider()
    
    else:
        st.write("Nenhuma mensagem no hist√≥rico ainda.")

st.markdown("### Chat Ativo")
container_chat = st.container(height = 500)

with container_chat:
    for i, msg in enumerate(st.session_state.chat_history):
        role = "ai" if isinstance(msg, AIMessage) else ("tool" if isinstance(msg, ToolMessage) else "user")
        
        avatar_icon = "üë§"
        sender_name = "Usu√°rio"
        message_role_for_streamlit = "user"

        if role == "ai":
            message_role_for_streamlit = "assistant"
            ai_message_index = sum(1 for m in st.session_state.chat_history[:i] if isinstance(m, AIMessage))
            is_groq_explicit = "@groq" in msg.content.lower()
            is_openai_explicit = "@openai" in msg.content.lower()
            msg_name = getattr(msg, 'name', None)
            
            if is_groq_explicit or (not is_openai_explicit and ai_message_index % 2 == 0 and not msg_name):
                 avatar_icon = "ü¶ô"
                 sender_name = "Groq (Llama3)"
            
            elif is_openai_explicit or (not is_groq_explicit and ai_message_index % 2 != 0 and not msg_name):
                 avatar_icon = "ü§î"
                 sender_name = "OpenAI (GPT)"
            
            elif msg_name:
                 avatar_icon = "‚ö†Ô∏è"
                 sender_name = f"Sistema ({msg_name})"
            
            else:
                 avatar_icon = "ü§ñ"
                 sender_name = "Assistente"

        elif role == "tool":
            message_role_for_streamlit = "assistant"
            avatar_icon = "üõ†Ô∏è"
            sender_name = "Ferramenta"

        with st.chat_message(message_role_for_streamlit, avatar=avatar_icon):
            if role == "tool":
                tool_name = getattr(msg, 'name', 'query_crm_database')
                st.markdown(f"**Resultado Ferramenta ({tool_name})**:")
                st.code(f"{msg.content}", language=None)
                st.caption(f"ID Chamada: {msg.tool_call_id}")
            
            elif role == "ai":
                st.markdown(f"**{sender_name}:**")
                if getattr(msg, 'tool_calls', None):
                    st.write(f"*Chamando ferramenta(s):*")
                    st.json([{'name': tc.get('name', 'N/A'), 'args': tc.get('args', {})} for tc in msg.tool_calls])
                st.markdown(msg.content)
            else:
                st.markdown(msg.content)

if prompt := st.chat_input("Fa√ßa uma pergunta sobre o CRM..."):
    st.session_state.chat_history.append(HumanMessage(content=prompt))
    st.rerun()

if st.session_state.chat_history and isinstance(st.session_state.chat_history[-1], HumanMessage):
    last_human_message = st.session_state.chat_history[-1]
    if not st.session_state.get("processing_lock", False):
        st.session_state["processing_lock"] = True
        current_state = {"messages": st.session_state.chat_history}

        with st.spinner("Consultando CRM e pensando..."):
            final_state = None

            try:
                final_state = st.session_state.app.invoke(current_state)
                if final_state and "messages" in final_state:
                    new_messages = final_state["messages"][len(current_state["messages"]):]
                    if new_messages:
                        st.session_state.chat_history.extend(new_messages)
                    else:
                        st.toast("O grafo n√£o retornou novas mensagens desta vez.", icon="ü§î")
                else:
                    st.toast("O grafo retornou um estado inv√°lido.", icon="error")
                    
                    st.session_state.chat_history.append(AIMessage(content="Desculpe, ocorreu um erro interno no estado do grafo."))
            
            except Exception as e:
                st.error(f"Erro durante a execu√ß√£o do grafo: {e}")
                st.session_state.chat_history.append(AIMessage(content=f"Desculpe, ocorreu um erro: {e}"))
            
            finally:
                st.session_state["processing_lock"] = False
                st.rerun()

st.sidebar.divider()
st.sidebar.title("Instru√ß√µes")

st.sidebar.markdown("""
Digite sua pergunta ao lado para conversar com os Agentes de IA.

Os Agentes s√£o capazes de consultar o banco de dados de CRM para extrair as respostas.

Tipos de perguntas:
- **Quais clientes est√£o ativos?**
- **Qual intera√ß√£o foi feita com Jo√£o Silva?**
- **Cite o nome de um dos clientes listados anteriormente.**
- **Quais clientes tiveram intera√ß√£o por e-mail?**
- **Algum cliente foi lead capturado com intera√ß√£o via formul√°rio do site?**
- **Quais intera√ß√µes ocorreram em 29-04-2025?**

IA Generativa comete erros. **SEMPRE** use seu conhecimento para verificar as respostas.
""")


