# ğŸ“„ğŸ’¬ Assistente RAG com PDFs (Retrieval-Augmented Generation)

Este projeto implementa um pipeline de **RAG (Retrieval-Augmented Generation)** utilizando **LangChain**, **FAISS**, **HuggingFace Embeddings** e **Streamlit**, permitindo a realizaÃ§Ã£o de perguntas em linguagem natural sobre documentos PDF carregados pelo usuÃ¡rio.

---

## ğŸš€ Funcionalidades

- Upload de arquivos PDF diretamente pela interface web.
- SegmentaÃ§Ã£o semÃ¢ntica dos documentos com `SemanticChunker`.
- VetorizaÃ§Ã£o dos chunks com `HuggingFaceEmbeddings` e armazenamento em `FAISS`.
- Respostas geradas por LLM (via API compatÃ­vel com OpenAI) com suporte a *source attribution*.
- Interface interativa construÃ­da com `Streamlit`.

---

## ğŸ§± Estrutura do Projeto

```
â”œâ”€â”€ main.py                   # Interface Streamlit
â”œâ”€â”€ rag_system.py            # Classe RAGSystem com toda a lÃ³gica do pipeline
â”œâ”€â”€ requirements.txt         # DependÃªncias do projeto
â””â”€â”€ README.md                # Este documento
```

---

## ğŸ§  Tecnologias Utilizadas

- **LangChain** (`langchain`, `langchain_community`, `langchain_openai`, `langchain_experimental`)
- **FAISS** â€“ indexaÃ§Ã£o vetorial local
- **HuggingFaceEmbeddings** â€“ modelo de embedding textual
- **ChatOpenAI** â€“ LLM customizado (via endpoint local)
- **PDFPlumberLoader** â€“ para leitura de PDFs
- **Streamlit** â€“ para frontend interativo

---

## âš™ï¸ Como Executar

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/seu_usuario/rag-pdf-assistant.git
cd rag-pdf-assistant
```

### 2. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

> âš ï¸ Certifique-se de que o endpoint da LLM estÃ¡ rodando (por exemplo, LM Studio em `http://192.168.0.27:1234/v1`).

### 3. Execute a aplicaÃ§Ã£o Streamlit

```bash
streamlit run main.py
```

---

## ğŸ“Œ ParÃ¢metros Importantes

Na classe `RAGSystem`, Ã© possÃ­vel configurar:

- `model_name`: Nome do modelo LLM compatÃ­vel com OpenAI.
- `api_base`: URL do endpoint da LLM.
- `api_key`: Chave de autenticaÃ§Ã£o (ou identificador de uso).
- `k_retrieval`: NÃºmero de chunks mais similares retornados pelo FAISS.

---

## âœ… Exemplo de Uso

1. FaÃ§a upload de um PDF via interface Streamlit.
2. Aguarde a construÃ§Ã£o do pipeline.
3. Digite uma pergunta relacionada ao conteÃºdo.
4. Receba a resposta com a indicaÃ§Ã£o das fontes utilizadas (trechos do PDF).

---

## ğŸ”’ ConsideraÃ§Ãµes de SeguranÃ§a

- O cÃ³digo roda **localmente** e nÃ£o envia arquivos ou textos para servidores externos (a menos que o endpoint LLM seja remoto).
- Ideal para uso em ambientes controlados, como laboratÃ³rios, clÃ­nicas, ambientes acadÃªmicos ou ambientes hospitalares com restriÃ§Ã£o de dados.

---

## ğŸ“š CrÃ©ditos e InspiraÃ§Ã£o

Este projeto foi inspirado por arquiteturas modernas de RAG utilizadas em soluÃ§Ãµes corporativas, adaptando pipelines do LangChain para cenÃ¡rios on-premise e edge.

---

## ğŸ§¾ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT â€“ sinta-se livre para utilizar, modificar e redistribuir.