# üß† Simple GraphRAG com LangGraph e LangChain

Este projeto demonstra uma implementa√ß√£o simples e modular de um pipeline GraphRAG utilizando [LangChain](https://www.langchain.com/) e [LangGraph](https://github.com/langchain-ai/langgraph), integrando PDF loader, FAISS e LLM local compat√≠vel com OpenAI.

---

## üì¶ Estrutura de Pastas

```
.
‚îú‚îÄ‚îÄ classic_rag.py          # Classe para carregar PDFs e construir vetor FAISS
‚îú‚îÄ‚îÄ graph_definition.py     # Orquestra√ß√£o dos n√≥s via LangGraph
‚îú‚îÄ‚îÄ graph_nodes.py          # Fun√ß√µes dos n√≥s do grafo
‚îú‚îÄ‚îÄ llm_model.py            # Instancia modelo LLM local (ex: LM Studio)
‚îú‚îÄ‚îÄ main.py                 # Executa o pipeline
‚îú‚îÄ‚îÄ state_agent.py          # Schema do estado compartilhado entre os n√≥s
‚îî‚îÄ‚îÄ documentos/             # (opcional) PDFs usados como fonte de dados
```

---

## üîÑ Pipeline (GraphRAG)

```mermaid
graph TD
    A[START] --> B[load_vectorstore]
    B --> C[retrieve_documents]
    C --> D[format_documents]
    D --> E[generate_answer]
    E --> F[END]
```

### Componentes do Pipeline:

| Etapa               | Fun√ß√£o T√©cnica                                                                 |
|---------------------|--------------------------------------------------------------------------------|
| `load_vectorstore`  | Cria ou carrega um FAISS index e retorna um retriever                          |
| `retrieve_documents`| Consulta documentos relevantes via retriever (`invoke(query)`)                 |
| `format_documents`  | Formata os metadados e conte√∫do dos documentos recuperados                     |
| `generate_answer`   | Injeta contexto em um prompt e utiliza o LLM para gerar a resposta final       |

---

## üöÄ Execu√ß√£o

### 1. Instalar depend√™ncias (exemplo b√°sico)
```bash
pip install langchain langgraph langchain-community langchain-huggingface faiss-cpu langchain-openai
```

### 2. Executar pipeline
```bash
python main.py
```

A sa√≠da ser√° a resposta final gerada pelo LLM com base nos PDFs e no estado do grafo.

---

## üß† Modelo Utilizado

```python
model_name = "meta-llama-3.1-8b-instruct@Q4_K_M"
api_base = "http://172.30.64.1:1234/v1"
```

Este projeto est√° configurado para usar **LM Studio** ou qualquer backend compat√≠vel com a API OpenAI.

---

## üìå Observa√ß√µes Finais

- O grafo √© definido de forma linear e did√°tica, ideal para ensino ou prototipagem r√°pida.
- Todos os n√≥s seguem o padr√£o de composi√ß√£o via `AgentState` com tipagem segura.
- Totalmente compat√≠vel com o LangChain 1.0 (usa `.invoke()` ao inv√©s de m√©todos legados).

---

## ‚ú® Autor

Desenvolvido por Felipe Meganha como base de estudo para GraphRAG.