
# ğŸ¤– Agentic RAG JurÃ­dico

Um agente de IA baseado em **LangGraph** e **LangChain**, especializado em **analisar contratos legais em PDF**. O sistema realiza recuperaÃ§Ã£o de contexto via busca vetorial (FAISS), formataÃ§Ã£o com metadados e geraÃ§Ã£o de respostas com LLM local (via LM Studio ou outro backend compatÃ­vel com OpenAI API).

---

## ğŸ§  VisÃ£o Geral

> â€œTransforme documentos jurÃ­dicos nÃ£o estruturados em conhecimento acessÃ­vel via linguagem natural.â€

Este agente Ã© capaz de:
- Carregar e indexar arquivos PDF de contratos;
- Fragmentar documentos e construir um Ã­ndice vetorial (FAISS);
- Recuperar automaticamente os trechos mais relevantes para uma pergunta;
- Gerar respostas contextualizadas usando um modelo LLM local (Meta Llama 3, por exemplo);
- Informar a origem da resposta com base nos metadados dos documentos.

---

## ğŸ”§ Tecnologias Utilizadas

| Tecnologia       | Finalidade                                |
|------------------|--------------------------------------------|
| LangChain        | Pipeline de RAG e abstraÃ§Ã£o de LLMs        |
| LangGraph        | OrquestraÃ§Ã£o baseada em fluxo de estados   |
| FAISS            | VetorizaÃ§Ã£o e busca semÃ¢ntica              |
| HuggingFace Hub  | Modelo de embedding (`all-mpnet-base-v2`)  |
| LM Studio / vLLM | Backend para servir modelos Llama 3        |
| PyPDFLoader      | Carregamento e parsing de PDFs             |

---

## ğŸ“ Estrutura do Projeto

```bash
project/
â”œâ”€â”€ main.py                      # Interface CLI do agente
â”œâ”€â”€ agentic_RAG.py              # Classe principal do sistema RAG
â”œâ”€â”€ workflow.py                 # DefiniÃ§Ã£o do fluxo LangGraph
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ agent_state.py
â”‚   â””â”€â”€ recupera_documentos.py
â”‚
â”œâ”€â”€ LLM/
â”‚   â”œâ”€â”€ formata_contexto.py
â”‚   â”œâ”€â”€ gera_resposta.py
â”‚   â”œâ”€â”€ prompt.py
â”‚   â””â”€â”€ llm_model.py
â”‚
â”œâ”€â”€ documentos/                 # Pasta com contratos em PDF
â””â”€â”€ dsavectordb/                # Base vetorial FAISS (gerada automaticamente)
```

---

## â–¶ï¸ Como Executar

### 1. **PrÃ©-requisitos**
- Python 3.10+
- Modelo LLM rodando via LM Studio, vLLM, Ollama ou OpenRouter
- Instalar dependÃªncias:

```bash
pip install -r requirements.txt
```

### 2. **Preparar a pasta de documentos**
Coloque seus arquivos PDF de contrato dentro da pasta `documentos/`. Exemplo:

```bash
project/
â”œâ”€â”€ documentos/
â”‚   â”œâ”€â”€ contrato_1.pdf
â”‚   â””â”€â”€ contrato_2.pdf
```

### 3. **Executar**
No terminal:

```bash
python main.py
```

VocÃª verÃ¡:

```
--- Inicializando o Agente de Contratos ---
Digite sua pergunta sobre os contratos (ou digite 'sair' para encerrar):
> Qual o prazo de vigÃªncia do contrato com a empresa X?
```

---

## ğŸ§­ Fluxo LangGraph

O fluxo Ã© composto por 3 nÃ³s principais:

```
[ retrieve ] â†’ [ format_context ] â†’ [ generate ] â†’ [ END ]
```

- **retrieve**: busca os trechos relevantes com base na pergunta
- **format_context**: concatena os trechos e adiciona metadados
- **generate**: gera a resposta com base no contexto e na pergunta

---

## âš™ï¸ ConfiguraÃ§Ã£o do LLM

A comunicaÃ§Ã£o com o modelo segue o padrÃ£o da OpenAI API. No arquivo `LLM/llm_model.py`, configure:

```python
model_name = "meta-llama-3.1-8b-instruct@Q4_K_M"
api_base = "http://localhost:1234/v1"
api_key = "lm-studio"
```

---

## ğŸ›¡ï¸ Exemplo de Prompt Usado

```text
VocÃª Ã© um assistente de IA especializado em analisar contratos legais.
Use o contexto recuperado dos documentos de contrato abaixo para responder Ã  pergunta.
...
```

---

## ğŸ’¡ PossÃ­veis ExtensÃµes

- ğŸ” HistÃ³rico de conversa multi-turno
- ğŸŒ Interface Web com Streamlit ou FastAPI
- ğŸ§  PersistÃªncia de logs de consulta
- ğŸ›‘ Filtros por tipo de contrato ou data
- ğŸ” Ajuste fino do modelo (finetuning)

---

## ğŸ“œ LicenÃ§a

MIT License. Livre para uso e modificaÃ§Ã£o.

---

## ğŸ¤ ContribuiÃ§Ãµes

Pull requests e sugestÃµes sÃ£o bem-vindos! Este projeto serve como base educacional e profissional para construÃ§Ã£o de agentes RAG robustos.
